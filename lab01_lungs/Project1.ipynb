{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9335cd",
   "metadata": {},
   "source": [
    "# Lungs Segmentation\n",
    "The segmentation of lungs may, possibly, proceed directly in 3D as follows:\n",
    "1. Run binarization of the CT image using a threshold of -320 HU – every voxel\n",
    "with HU lower than this threshold should receive label 1 (air label) and the\n",
    "remaining voxels should receive label 0\n",
    "2. Use body mask to select only air regions within body\n",
    "3. Design a sequence of morphological (and other appropriate) operations to fill\n",
    "the holes in the interior of lungs and to remove ‘air’ clusters which do not\n",
    "correspond to lungs (e.g. gas in bowels) – at the end one should be left with\n",
    "clusters which correspond only to airways\n",
    "4. Use watershed from markers (scikit-image -> segmentation -> watershed) to\n",
    "extract the left and the right lung from the segmentation being the result of step\n",
    "(3) above. Before using watershed design a procedure for defining the three\n",
    "markers (marker of left lung, marker of right lung, marker of background).\n",
    "5. To compare segmentation results with reference segmentations available at\n",
    "Lab One Drive use Dice coefficient and Hausdorff distance (find the definitions of\n",
    "these   quantities)   as   implemented   in   surface-distance   [package](https://github.com/google-deepmind/surface-distance).\n",
    "The project results (Dice coefficients and Hausdorff distance) should be\n",
    "reported   for   the   three   tasks:   body   mask   segmentation,   left   lung\n",
    "segmentation, right lung segmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c574f0ef",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa0823d5-19e4-4f17-9bf8-8950f9e194bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "from skimage import morphology, measure\n",
    "from skimage.segmentation import watershed\n",
    "from skimage import filters\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "# from pycimg import CImg\n",
    "\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import reconstruction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84315969",
   "metadata": {},
   "source": [
    "TODO\n",
    "#body\n",
    "Body:\n",
    "binarization\n",
    "opening\n",
    "flood_fill\n",
    "\n",
    "#binarize lungs\n",
    "Do histogram of the image\n",
    "do kmeans to get threashold\n",
    "do binarization with threashold\n",
    "\n",
    "#lung segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6afc10",
   "metadata": {},
   "source": [
    "## Load / save .nii files and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60dc8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii_gz_file(file_path: str) -> tuple:\n",
    "    nii_img = nib.load(file_path)\n",
    "    nii_data = nii_img.get_fdata()\n",
    "    return nii_data, nii_img.affine\n",
    "\n",
    "def save_to_nii(segmented_data: np.ndarray, affine: np.ndarray, output_path: str) -> None:\n",
    "    segmented_nii = nib.Nifti1Image(segmented_data.astype(np.uint8), affine)\n",
    "    nib.save(segmented_nii, output_path)\n",
    "    \n",
    "def view_nii_data(nii_data: np.ndarray) -> None:\n",
    "    for i in range(nii_data.shape[2]):\n",
    "        cv2.imshow('slice', nii_data[:, :, i])\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def visualize_photos(original: np.ndarray, segmented: np.ndarray, reference: np.ndarray, *slices: int) -> None:\n",
    "    num_slices = len(slices)\n",
    "    plt.figure(figsize=(15, 5 * num_slices))  # Adjust figure size based on the number of slices\n",
    "\n",
    "    for i, slice_num in enumerate(slices):\n",
    "        # Original slice\n",
    "        plt.subplot(num_slices, 3, 3 * i + 1)\n",
    "        plt.title(f\"Original Slice {slice_num}\")\n",
    "        plt.imshow(original[:, :, slice_num], cmap=\"gray\")\n",
    "        \n",
    "        # Segmented slice\n",
    "        plt.subplot(num_slices, 3, 3 * i + 2)\n",
    "        plt.title(f\"Segmented Slice {slice_num}\")\n",
    "        plt.imshow(segmented[:, :, slice_num], cmap=\"gray\")\n",
    "        \n",
    "        # Reference slice\n",
    "        plt.subplot(num_slices, 3, 3 * i + 3)\n",
    "        plt.title(f\"Reference Slice {slice_num}\")\n",
    "        plt.imshow(reference[:, :, slice_num], cmap=\"gray\")\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9bca1e",
   "metadata": {},
   "source": [
    "## 1. Body differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49834f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transforms:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def binarize_images(self, image: np.ndarray, threshold: float = -320, use_otsu: bool = False) -> np.ndarray:\n",
    "        threshold = filters.threshold_otsu(image) if use_otsu else threshold\n",
    "        image = np.where(image < threshold, 1, 0)\n",
    "        return image.astype(np.uint8)\n",
    "    \n",
    "    def binarize_images_kmeans(self, image: np.ndarray, max_iter: int = 100) -> float:\n",
    "        min_val = image.min()\n",
    "        not_background = image > min_val\n",
    "        img_not_background = image * not_background\n",
    "        \n",
    "        threshold = img_not_background.sum() / not_background.sum()\n",
    "        prev_threshold = 0\n",
    "        \n",
    "        plt.imshow(not_background[..., 70], cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        for _ in range(max_iter):\n",
    "            foreground_mask = image > threshold\n",
    "            background_mask = image <= threshold\n",
    "            \n",
    "            foreground = img_not_background * foreground_mask\n",
    "            background = img_not_background * background_mask\n",
    "            \n",
    "            avg_foreground = foreground.sum() / foreground_mask.sum()\n",
    "            avg_background = background.sum() / background_mask.sum()\n",
    "            \n",
    "            new_threshold = (avg_foreground + avg_background) / 2\n",
    "            \n",
    "            if abs(new_threshold - prev_threshold) < 0.1:\n",
    "                threshold = new_threshold\n",
    "                break\n",
    "            \n",
    "            prev_threshold = threshold\n",
    "            threshold = new_threshold\n",
    "        \n",
    "        print(f\"threshold: {threshold}\")\n",
    "            \n",
    "        image = (image > threshold) * not_background\n",
    "        \n",
    "        plt.imshow(image[..., 70], cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        return image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1cb0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import flood\n",
    "class BodyMask(Transforms):\n",
    "    def __init__(self, image: np.ndarray) -> None:\n",
    "        self.img: np.ndarray = image\n",
    "        \n",
    "    def initial_transform(self) -> np.ndarray:\n",
    "        binary_image = self.binarize_images_kmeans(self.img)\n",
    "        opened_img = morphology.binary_opening(binary_image, morphology.ball(2))\n",
    "        self.img = opened_img\n",
    "        \n",
    "    \n",
    "    def reconstruct_3d(self) -> np.ndarray:\n",
    "        seed = np.zeros_like(mask)\n",
    "        list_of_corners = [(0, 0, 0), (0, 0, -1), (0, -1, 0), (-1, 0, 0), (-1, -1, -1), (-1, -1, 0), (-1, 0, -1), (0, -1, -1)]\n",
    "        for corner in list_of_corners:\n",
    "            seed[corner] = 1\n",
    "            \n",
    "        labels = label(self.img, connectivity=1)\n",
    "        regions = regionprops(labels)\n",
    "        largest_region = max(regions, key=lambda x: x.area)\n",
    "        largest_region_mask = labels == largest_region.label\n",
    "        \n",
    "        mask = largest_region_mask\n",
    "        neg_mask = np.logical_not(mask)\n",
    "        \n",
    "        reconstructed = reconstruction(seed, neg_mask)\n",
    "        neg_reconstructed = 1 - reconstructed\n",
    "        \n",
    "        return neg_reconstructed\n",
    "    \n",
    "    def flood_fill_3d(self, seed_point: tuple = (0, 0, 0)) -> np.ndarray:\n",
    "        labels = label(self.img, connectivity=1)\n",
    "        regions = regionprops(labels)\n",
    "        largest_region = max(regions, key=lambda x: x.area)\n",
    "        \n",
    "        neg_mask = (labels == largest_region.label) * 1\n",
    "        mask = flood(neg_mask, seed_point)\n",
    "        mask = np.logical_not(mask)\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124c272",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79be8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(img_path: str,reference_img_path: str, body_mask_path: str, output_path: str, ) -> None:\n",
    "    # load images\n",
    "    img, affine = load_nii_gz_file(img_path)\n",
    "    body_masks, _ = load_nii_gz_file(body_mask_path)\n",
    "    reference_img, _ = load_nii_gz_file(reference_img_path)\n",
    "\n",
    "    # transform\n",
    "    body = BodyMask(img)\n",
    "    body.initial_transform()\n",
    "    body_mask = body.reconstruct_3d()\n",
    "    \n",
    "    visualize_photos(body_mask, body_masks, abs(body_mask - body_masks), 50, 70, 100, 120)\n",
    "    # print(\"Dice_coefficient, Hausdorff_distance\", calculate_score(imgs_transform, reference_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa21911",
   "metadata": {},
   "source": [
    "## Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c399b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('Images/IMG_0001.nii.gz','ReferenceSegmentations/LUNGS_IMG_0001.nii.gz', 'BodyMasks/BODYMASK_IMG_0001.nii.gz', 'output.nii.gz')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
