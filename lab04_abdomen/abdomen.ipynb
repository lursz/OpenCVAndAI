{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torchvision.models import DenseNet121_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(data):\n",
    "    num_charts = len(data)\n",
    "    ncols = 4\n",
    "    nrows = (num_charts + ncols - 1) // ncols\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols * 4, nrows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, sublist in enumerate(data):\n",
    "        sublist_data, start, end, filename = sublist\n",
    "        x_indices = range(len(sublist_data))\n",
    "        \n",
    "        # Plot on the current axis\n",
    "        axes[i].bar(x_indices, sublist_data, color='blue', alpha=0.7)\n",
    "        axes[i].axvline(x=start, color='red', linestyle='-', linewidth=1.5, label='Start')\n",
    "        axes[i].axvline(x=end, color='red', linestyle='-', linewidth=1.5, label='End')\n",
    "        \n",
    "        axes[i].set_title(f'{filename}', fontsize=12)\n",
    "        axes[i].set_xlabel('Index', fontsize=10)\n",
    "        axes[i].set_ylabel('Value', fontsize=10)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def view_nii_pic(nii_data: np.ndarray) -> None:\n",
    "    for i in range(nii_data.shape[2]):\n",
    "        cv2.imshow('slice', nii_data[:, :, i])\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def visualize_photo(img: np.ndarray, photo_title: str, *slices: int) -> None:\n",
    "    print(f\"Visualizing {photo_title}\")\n",
    "    plt.figure(figsize=(5 * len(slices), 5)) \n",
    "    \n",
    "    for i, slice_num in enumerate(slices):\n",
    "        plt.subplot(1, len(slices), i + 1)\n",
    "        plt.title(f\"photo Slice {slice_num}\")\n",
    "        plt.imshow(img[:, :, slice_num], cmap=\"gray\")\n",
    "        \n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "  \n",
    "    \n",
    "def visualize_photos(original: np.ndarray, segmented: np.ndarray, reference: np.ndarray, *slices: int) -> None:\n",
    "    num_slices = len(slices)\n",
    "    plt.figure(figsize=(15, 5 * num_slices))  # Adjust figure size based on the number of slices\n",
    "\n",
    "    for i, slice_num in enumerate(slices):\n",
    "        # Original slice\n",
    "        plt.subplot(num_slices, 3, 3 * i + 1)\n",
    "        plt.title(f\"Original Slice {slice_num}\")\n",
    "        plt.imshow(original[:, :, slice_num], cmap=\"gray\")\n",
    "        \n",
    "        # Segmented slice\n",
    "        plt.subplot(num_slices, 3, 3 * i + 2)\n",
    "        plt.title(f\"Segmented Slice {slice_num}\")\n",
    "        plt.imshow(segmented[:, :, slice_num], cmap=\"gray\")\n",
    "        \n",
    "        # Reference slice\n",
    "        plt.subplot(num_slices, 3, 3 * i + 3)\n",
    "        plt.title(f\"Reference Slice {slice_num}\")\n",
    "        plt.imshow(reference[:, :, slice_num], cmap=\"gray\")\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "    \n",
    "def plot_histogram(img: np.ndarray) -> None:\n",
    "    plt.hist(img.ravel(), bins=256, range=(img.min()+1, img.max()-1), fc='k', ec='k')\n",
    "    plt.axvline(x=-320, color='red', linestyle='--', linewidth=1.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdomenDataset(Dataset):\n",
    "    def __init__(self, filepath: str, label_filepath: str, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data: list = self._load_nii_gz_files(filepath)\n",
    "        self.labels: list = self._load_labels_file(label_filepath)\n",
    "        \n",
    "        self.frames_list: list = []\n",
    "        self.labels_list: list = []\n",
    "        \n",
    "        self.positive_count = 0\n",
    "        \n",
    "        for file_name, img in self.data:\n",
    "            print(f\"loading {file_name}\")\n",
    "            end, begin = self.labels[file_name]\n",
    "            for i in range(0, img.shape[2]):\n",
    "                self.frames_list.append(img[:, :, i])\n",
    "                self.labels_list.append(1 if begin <= i <= end else 0)\n",
    "                self.positive_count += self.labels_list[-1]\n",
    "                \n",
    "        print(f\"Loaded {len(self.frames_list)} frames\")\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.frames_list)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        img = self.frames_list[idx]\n",
    "        label = float(self.labels_list[idx])\n",
    "        \n",
    "        img = torch.tensor(img).float().unsqueeze(0)\n",
    "        img = self.transform(img)            \n",
    "        return img.repeat(3, 1, 1), label\n",
    "        \n",
    "        \n",
    "    def _load_labels_file(self, label_filepath: str) -> dict:\n",
    "        labels: list = {}\n",
    "        with open(label_filepath, 'r') as file:\n",
    "            for line in file:\n",
    "                file_name, end, begin = line.split()\n",
    "                labels[file_name] = (int(end), int(begin))\n",
    "        return labels\n",
    "    \n",
    "    def _load_nii_gz_files(self, filepath) -> list:\n",
    "        data: list = []\n",
    "        for file_name in os.listdir(filepath):\n",
    "            if file_name.endswith('.nii.gz'):\n",
    "                file_path = os.path.join(filepath, file_name)\n",
    "                nii_img = nib.load(file_path)\n",
    "                nii_data = nii_img.get_fdata()  # img as numpy array\n",
    "                data.append((file_name, nii_data))\n",
    "        return data\n",
    "    \n",
    "    \n",
    "class AbdomenSingleDataset(Dataset):\n",
    "    def __init__(self, filepath: str, filename: str, transform=None):\n",
    "        self.transform = transform\n",
    "        self.original_img: list = self._load_file(filepath, filename)\n",
    "        self.frames_list: list = [self.original_img[:, :, i] for i in range(self.original_img.shape[2])]\n",
    "        print(f\"Loaded {len(self.frames_list)} frames\")\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.frames_list)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        img = self.frames_list[idx]\n",
    "        img = torch.tensor(img).float().unsqueeze(0)\n",
    "        img = self.transform(img)            \n",
    "        return img.repeat(3, 1, 1)\n",
    "    \n",
    "    def _load_file(self, filepath: str, filename: str) -> list:   \n",
    "        f = os.path.join(filepath, filename)\n",
    "        nii_img = nib.load(f)\n",
    "        nii_data = nii_img.get_fdata()\n",
    "        return nii_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdomenModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(AbdomenModel, self).__init__()\n",
    "        self.densenet = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        self.freeze_densenet()\n",
    "        self.densenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(self.densenet.classifier.in_features, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        x = self(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n",
    "    \n",
    "    def unfreeze_densenet(self) -> None:\n",
    "        for param in self.densenet.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def freeze_densenet(self) -> None:\n",
    "        for param in self.densenet.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model: AbdomenModel, criterion: torch.nn.Module, optimizer: Optimizer, dataloader: dict, EPOCHS: int = 10):\n",
    "    accuracy_history: list = []\n",
    "    loss_history: list = []\n",
    "    val_accuracy_history: list = []\n",
    "    val_loss_history: list = []\n",
    "    \n",
    "    sigm = nn.Sigmoid()\n",
    "    \n",
    "    for epoch in range(EPOCHS):    \n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in tqdm(dataloader['train']):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze(dim=-1)\n",
    "            outputs_sigm = sigm(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            preds = (outputs_sigm > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = running_loss / len(dataloader['train'])\n",
    "        train_accuracy = correct / total\n",
    "        loss_history.append(train_loss)\n",
    "        accuracy_history.append(train_accuracy)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(dataloader['val']):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "                \n",
    "                outputs = model(inputs).squeeze(dim=-1)\n",
    "                outputs_sigm = sigm(outputs)\n",
    "            \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = (outputs_sigm > 0.5).float()\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_loss = val_loss / len(dataloader['val'])\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_accuracy_history.append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "    return model, [accuracy_history, loss_history, val_accuracy_history, val_loss_history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0007_1_.nii.gz\n",
      "loading 0003_1_.nii.gz\n",
      "loading 0004_1_.nii.gz\n",
      "loading 0008_2_.nii.gz\n",
      "loading 0007_2_.nii.gz\n",
      "loading 0006_2_.nii.gz\n",
      "loading 0004_2_.nii.gz\n",
      "loading 0001_1_.nii.gz\n",
      "loading 0002_2_.nii.gz\n",
      "loading 0008_1_.nii.gz\n",
      "loading 0006_1_.nii.gz\n",
      "loading 0002_1_.nii.gz\n",
      "loading 0001_2_.nii.gz\n",
      "loading 0005_1_.nii.gz\n",
      "loading 0003_2_.nii.gz\n",
      "Loaded 3809 frames\n",
      "loading 0010_2_.nii.gz\n",
      "loading 0010_1_.nii.gz\n",
      "loading 0009_2_.nii.gz\n",
      "loading 0009_1_.nii.gz\n",
      "Loaded 1052 frames\n"
     ]
    }
   ],
   "source": [
    "transform_val = torchvision.transforms.Compose([\n",
    "    lambda x: (x + 1024) / 3072,\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    lambda x: (x + 1024) / 3072,\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.RandomRotation(40),\n",
    "    torchvision.transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    torchvision.transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "datasets = {\n",
    "    \"train\": AbdomenDataset('data/train', 'data/oznaczenia.txt', transform=transform),\n",
    "    \"val\": AbdomenDataset('data/val', 'data/oznaczenia.txt', transform=transform_val),\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(datasets[\"train\"], batch_size=8, shuffle=True),\n",
    "    \"val\": DataLoader(datasets[\"val\"], batch_size=8, shuffle=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3809\n",
      "6.618\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets['train']))\n",
    "scaling_weight = (len(datasets['train']) - datasets['train'].positive_count) / datasets['train'].positive_count\n",
    "print(scaling_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AbdomenModel().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([scaling_weight], device=device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = training_loop(model, criterion, optimizer, dataloaders, EPOCHS=5)\n",
    "model.unfreeze_densenet()\n",
    "model, history = training_loop(model, criterion, optimizer, dataloaders, EPOCHS=55)\n",
    "torch.save(model.state_dict(), f\"results/model_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{max(history[2])}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Abdomen Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_window_of_abdomen(list_of_probabilities: list) -> tuple[int, int]:\n",
    "    epsilon = 1e-10\n",
    "    log_proba = np.log(np.clip(list_of_probabilities, epsilon, 1))\n",
    "    log_proba_rev = np.log(np.clip(1 - np.array(list_of_probabilities), epsilon, 1))\n",
    "    \n",
    "    best_begin = 0\n",
    "    best_end = 0\n",
    "    best_value = -np.inf\n",
    "    \n",
    "    for start in range(len(list_of_probabilities)):\n",
    "        for end in range(start, len(list_of_probabilities)):\n",
    "            sum_log = np.sum(log_proba[start:end+1])\n",
    "            sum_rev_rest = np.sum(log_proba_rev[end + 1:]) + np.sum(log_proba_rev[:start])\n",
    "            value = sum_log + sum_rev_rest\n",
    "            \n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_begin = start\n",
    "                best_end = end\n",
    "                \n",
    "    return best_begin, best_end\n",
    "    \n",
    "\n",
    "def naive_select_abdomen_window(list_of_probabilities: list) -> tuple[int, int]:\n",
    "    size = 30\n",
    "    \n",
    "    max_value = float('-inf')\n",
    "    left, right = 0, size\n",
    "    \n",
    "    for i in range(len(list_of_probabilities) - size):\n",
    "        value = sum(list_of_probabilities[i:i + size])\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            left, right = i, i + size\n",
    "            \n",
    "    return left, right\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(filepath: str) -> list:\n",
    "    dataloaders: list = []\n",
    "    for file_name in os.listdir(filepath):\n",
    "        if file_name.endswith('.nii.gz'):\n",
    "            dataloader = DataLoader(AbdomenSingleDataset(filepath, file_name, transform=transform_val))\n",
    "            dataloaders.append((dataloader, file_name))\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "def load_labeled_scores(label_filepath: str) -> dict:\n",
    "        labels: list = {}\n",
    "        with open(label_filepath, 'r') as file:\n",
    "            for line in file:\n",
    "                file_name, end, begin = line.split()\n",
    "                labels[file_name] = (int(end), int(begin))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to evaluate all scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(filepath: str) -> list:\n",
    "    model_path = \"results/model_2024-12-10_18-43-51_0.9933460076045627.pt\"\n",
    "    model = AbdomenModel().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    sigm = nn.Sigmoid()\n",
    "    outputs = []\n",
    "    dataloaders = create_dataloaders(filepath)\n",
    "\n",
    "    for dataloader, file_name in dataloaders:\n",
    "        dl_output = []\n",
    "        for data in tqdm(dataloader):\n",
    "            inputs = data\n",
    "            inputs = inputs.to(device)\n",
    "            fragment_outputs = model(inputs).squeeze(dim=-1)\n",
    "            fragment_outputs_sigm = sigm(fragment_outputs)\n",
    "            dl_output.append(fragment_outputs_sigm.tolist()[0])\n",
    "        \n",
    "        outputs.append((dl_output, file_name))\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1331806/3955275334.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 207 frames\n",
      "Loaded 267 frames\n",
      "Loaded 267 frames\n",
      "Loaded 311 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:01<00:00, 108.33it/s]\n",
      "100%|██████████| 267/267 [00:02<00:00, 109.19it/s]\n",
      "100%|██████████| 267/267 [00:02<00:00, 108.80it/s]\n",
      "100%|██████████| 311/311 [00:02<00:00, 108.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 0010_2_.nii.gz with start: 104, end: 135, label_start: 104, label_end: 134\n",
      "File 0010_2_.nii.gz, score: 1\n",
      "File 0010_1_.nii.gz with start: 167, end: 195, label_start: 168, label_end: 197\n",
      "File 0010_1_.nii.gz, score: 3\n",
      "File 0009_2_.nii.gz with start: 171, end: 213, label_start: 173, label_end: 212\n",
      "File 0009_2_.nii.gz, score: 3\n",
      "File 0009_1_.nii.gz with start: 182, end: 220, label_start: 183, label_end: 219\n",
      "File 0009_1_.nii.gz, score: 2\n"
     ]
    }
   ],
   "source": [
    "labeled_scores = load_labeled_scores('data/oznaczenia.txt')\n",
    "calculated_outputs = evaluate_model('data/val')\n",
    "\n",
    "for output, file_name in calculated_outputs:\n",
    "    label_end, label_start = labeled_scores[file_name]\n",
    "    start, end = select_window_of_abdomen(output)\n",
    "    print(f\"File {file_name} with start: {start}, end: {end}, label_start: {label_start}, label_end: {label_end}\")\n",
    "    score = abs(start - label_start) + abs(end - label_end)\n",
    "    print(f\"File {file_name}, score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = load_labeled_scores('data/oznaczenia.txt')\n",
    "plot_data = [(calculated_outputs[i][0], labels[calculated_outputs[i][1]][1], labels[calculated_outputs[i][1]][0], calculated_outputs[i][1]) for i in range(len(calculated_outputs))]\n",
    "plot_graph(plot_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
